{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://apache.osuosl.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!ls\n",
        "\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "\n",
        "!pwd\n",
        "!ls /content/\n",
        "\n",
        "# Set up Spark\n",
        "!pip install -q findspark\n",
        "!pip install py4j\n",
        "\n",
        "!export JAVA_HOME=$(/usr/lib/jvm/java-8-openjdk-amd64 -v 1.8)\n",
        "! echo $JAVA_HOME\n",
        "import os\n",
        "\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init(\"spark-3.1.2-bin-hadoop3.2\")# SPARK_HOME\n",
        "\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzpXtNAviq8Z",
        "outputId": "0bd03c2d-e75f-4860-a264-f795b83bbc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,820 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,450 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,228 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [933 kB]\n",
            "Get:24 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.9 kB]\n",
            "Fetched 12.9 MB in 5s (2,810 kB/s)\n",
            "Reading package lists... Done\n",
            "sample_data  spark-3.1.2-bin-hadoop3.2.tgz  train.csv\n",
            "/content\n",
            "sample_data\t\t   spark-3.1.2-bin-hadoop3.2.tgz\n",
            "spark-3.1.2-bin-hadoop3.2  train.csv\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 6.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j\n",
            "Successfully installed py4j-0.10.9.3\n",
            "/bin/bash: /usr/lib/jvm/java-8-openjdk-amd64: Is a directory\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF_kSfCH3VwP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "import numpy as np\n",
        "from pyspark.ml import Transformer, Pipeline, Estimator\n",
        "from pyspark.ml.feature import *\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep_Y5n1C3VwS",
        "outputId": "fe3c66fb-3480-4e32-d4ee-98ff87643ced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running...\n",
            "finished\n"
          ]
        }
      ],
      "source": [
        "#data preprocessing\n",
        "print('running...')\n",
        "session=SparkSession.builder.appName(\"Spark SQL\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()\n",
        "data=session.read.options(inferSchema=True,header=True).csv('/content/train.csv').toDF(\"jobType\",\"degree\",\"major\",\n",
        "\"industry\",\"yearsExperience\",\"milesFromMetropolis\",\"label\")\n",
        "print('finished')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbUJglcskdPE",
        "outputId": "08765a6e-f79d-40f7-81f3-b37083bb40c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+----------+---------+---------------+-------------------+------+\n",
            "|       jobType|     degree|     major| industry|yearsExperience|milesFromMetropolis|salary|\n",
            "+--------------+-----------+----------+---------+---------------+-------------------+------+\n",
            "|           CFO|    MASTERS|      MATH|   HEALTH|             10|                 83|   130|\n",
            "|           CEO|HIGH_SCHOOL|      NONE|      WEB|              3|                 73|   101|\n",
            "|VICE_PRESIDENT|   DOCTORAL|   PHYSICS|   HEALTH|             10|                 38|   137|\n",
            "|       MANAGER|   DOCTORAL| CHEMISTRY|     AUTO|              8|                 17|   142|\n",
            "|VICE_PRESIDENT|  BACHELORS|   PHYSICS|  FINANCE|              8|                 16|   163|\n",
            "|       MANAGER|   DOCTORAL|   COMPSCI|  FINANCE|              2|                 31|   113|\n",
            "|           CFO|       NONE|      NONE|   HEALTH|             23|                 24|   178|\n",
            "|        JUNIOR|  BACHELORS| CHEMISTRY|EDUCATION|              9|                 70|    73|\n",
            "|       JANITOR|HIGH_SCHOOL|      NONE|EDUCATION|              1|                 54|    31|\n",
            "|VICE_PRESIDENT|  BACHELORS| CHEMISTRY|     AUTO|             17|                 68|   104|\n",
            "|       JANITOR|HIGH_SCHOOL|      NONE|   HEALTH|             24|                 30|   102|\n",
            "|           CEO|    MASTERS|   PHYSICS|EDUCATION|              7|                 79|   144|\n",
            "|        JUNIOR|       NONE|      NONE|      OIL|              8|                 29|    79|\n",
            "|        JUNIOR|    MASTERS|      MATH|  FINANCE|             21|                 26|   193|\n",
            "|       JANITOR|       NONE|      NONE|     AUTO|             21|                 81|    47|\n",
            "|           CTO|    MASTERS|   BIOLOGY|  SERVICE|             13|                  8|   172|\n",
            "|        JUNIOR|    MASTERS|   PHYSICS|  SERVICE|              1|                 91|    47|\n",
            "|VICE_PRESIDENT|    MASTERS|LITERATURE|  SERVICE|             23|                 43|   126|\n",
            "|           CEO|    MASTERS|LITERATURE|  SERVICE|             23|                 66|   122|\n",
            "|           CEO|    MASTERS|   PHYSICS|EDUCATION|              9|                 99|    95|\n",
            "+--------------+-----------+----------+---------+---------------+-------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode"
      ],
      "metadata": {
        "id": "WPtgaUTOn1O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stages=[]\n",
        "categoricalColumns=[\"jobType\",\"degree\",\"major\",\"industry\"]\n",
        "for categoricalCol in categoricalColumns:\n",
        "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
        "    stages += [stringIndexer, encoder]\n",
        "\n",
        "numericCols = [\"yearsExperience\",\"milesFromMetropolis\"]\n",
        "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]\n",
        "\n",
        "pipeline = Pipeline(stages=stages)\n",
        "pipelineModel = pipeline.fit(data)\n",
        "preppedDataDF = pipelineModel.transform(data)\n",
        "preppedDataDF.printSchema()\n",
        "\n",
        "cols = data.columns\n",
        "selectedcols = [\"label\",\"features\"]\n",
        "dataset = preppedDataDF.select(selectedcols)\n",
        "\n",
        "train,test=dataset.randomSplit([0.7,0.3],seed=100)\n",
        "print(train.count())\n",
        "#print(test.count())\n",
        "train.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNEJ8V2vnzQT",
        "outputId": "0bcbf1e8-82f6-49bc-e439-27e166e73367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- jobType: string (nullable = true)\n",
            " |-- degree: string (nullable = true)\n",
            " |-- major: string (nullable = true)\n",
            " |-- industry: string (nullable = true)\n",
            " |-- yearsExperience: integer (nullable = true)\n",
            " |-- milesFromMetropolis: integer (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- jobTypeIndex: double (nullable = false)\n",
            " |-- jobTypeclassVec: vector (nullable = true)\n",
            " |-- degreeIndex: double (nullable = false)\n",
            " |-- degreeclassVec: vector (nullable = true)\n",
            " |-- majorIndex: double (nullable = false)\n",
            " |-- majorclassVec: vector (nullable = true)\n",
            " |-- industryIndex: double (nullable = false)\n",
            " |-- industryclassVec: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n",
            "699966\n",
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|   17|(27,[4,8,11,22,26...|\n",
            "|   18|(27,[4,7,11,22,25...|\n",
            "|   18|(27,[4,8,11,22,26...|\n",
            "|   19|(27,[4,7,11,22,26...|\n",
            "|   19|(27,[4,8,11,22,25...|\n",
            "|   19|(27,[4,8,11,22,26...|\n",
            "|   19|(27,[4,8,11,22,26...|\n",
            "|   20|(27,[4,7,11,22,25...|\n",
            "|   20|(27,[4,7,11,22,25...|\n",
            "|   20|(27,[4,7,11,22,25...|\n",
            "|   20|(27,[4,7,11,22,26...|\n",
            "|   20|(27,[4,7,11,22,26...|\n",
            "|   20|(27,[4,7,11,22,26...|\n",
            "|   20|(27,[4,7,11,22,26...|\n",
            "|   20|(27,[4,8,11,22,25...|\n",
            "|   20|(27,[4,8,11,22,25...|\n",
            "|   20|(27,[4,8,11,22,25...|\n",
            "|   20|(27,[4,8,11,22,25...|\n",
            "|   20|(27,[4,8,11,22,25...|\n",
            "|   20|(27,[4,8,11,22,25...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "KbeK30_IpqEa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YnY4ZLt3VwU",
        "outputId": "b22df529-dc96-4f71-c7a7-1371cdf9a3b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------------------+\n",
            "|label|            features|        prediction|\n",
            "+-----+--------------------+------------------+\n",
            "|   19|(27,[4,7,11,22,25...|20.679534799762806|\n",
            "|   20|(27,[4,7,11,22,25...|16.353561402897057|\n",
            "|   20|(27,[4,7,11,22,25...| 19.89561070439568|\n",
            "|   20|(27,[4,7,11,22,26...|19.474866912018953|\n",
            "|   20|(27,[4,7,11,22,26...|19.082904864335404|\n",
            "|   20|(27,[4,7,11,22,26...|15.163284387499786|\n",
            "|   20|(27,[4,7,11,22,26...|14.771322339816223|\n",
            "|   20|(27,[4,8,11,22,25...|13.096137336200812|\n",
            "|   20|(27,[4,8,11,22,26...|18.177253083740524|\n",
            "|   20|(27,[4,8,11,22,26...|13.865670559221343|\n",
            "|   21|(27,[4,7,11,22,25...| 24.97672645193542|\n",
            "|   21|(27,[4,7,11,22,25...|  21.0571059750998|\n",
            "|   21|(27,[4,7,11,22,25...|20.273181879732675|\n",
            "|   21|(27,[4,7,11,22,25...|19.881219832049112|\n",
            "|   21|(27,[4,7,11,22,25...|17.921409593631296|\n",
            "|   21|(27,[4,7,11,22,26...| 29.27391810410802|\n",
            "|   21|(27,[4,7,11,22,26...| 14.37936029213266|\n",
            "|   21|(27,[4,8,11,22,26...|20.920987417525467|\n",
            "|   21|(27,[4,8,11,22,26...| 17.78529103605696|\n",
            "|   22|(27,[4,7,11,22,25...| 26.15261259498611|\n",
            "+-----+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "LR Test set RMSE =  19.7213080340121\n"
          ]
        }
      ],
      "source": [
        "#Learning\n",
        "#LinearRegression model, maxIter=10\n",
        "LR = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "LRmodel = LR.fit(train)\n",
        "\n",
        "predictions = LRmodel.transform(test)\n",
        "predictions.show()\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "RMSE = evaluator.evaluate(predictions)\n",
        "print(\"LR Test set RMSE = \",RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ImjLnebrGzb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Spark_SalaryPredict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}